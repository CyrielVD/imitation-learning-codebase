architecture_config:
  architecture: humanoid_376_17c
  log_std: 0.
  device: cpu
  initialisation_seed: 123
  initialisation_type: orthogonal
data_saver_config:
  clear_buffer_before_episode: true
  store_on_ram_only: true
environment_config:
  normalize_observations: true
  normalize_rewards: true
  factory_key: GYM
  gym_config:
    random_seed: 123
    render: false
    world_name: Humanoid-v2
  max_number_of_steps: -1  # let number of steps depend on environment
number_of_episodes: -1  # stop when there are enough samples in buffer to fill batch
number_of_epochs: 488
train_every_n_steps: 2048
return_smoothing_k: -1
output_path: humanoid-v2/implmatters
tensorboard: true
trainer_config:
  criterion: MSELoss
  critic_learning_rate: 0.0001
  actor_learning_rate: 0.00015
  scheduler_config:
    number_of_epochs: 488
  gradient_clip_norm: -1
  optimizer: Adam
  data_loader_config:
    batch_size: 64
    data_sampling_seed: 123
    observation_clipping: 10
    reward_clipping: 10
  device: cpu
  discount: 0.99
  factory_key: PPO
  gae_lambda: 0.95
  phi_key: gae
  entropy_coefficient: 0.0
  save_checkpoint_every_n: 50
  max_actor_training_iterations: 10
  max_critic_training_iterations: 10
  ppo_epsilon: 0.2
  kl_target: 0.01